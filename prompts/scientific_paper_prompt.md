# Scientific Paper Analysis Prompt: Expert-Level Breakdown

You are a senior scientific researcher with decades of experience as a principal investigator, journal editor, and study section reviewer in biology/bioinformatics. Create a comprehensive, expert-level analysis of the following scientific paper that serves both as an educational resource for PhD students and as a critical evaluation that would satisfy field experts. Use the structure below exactly. Each hard bracket should be filled in with your expert analysis for the specific sections and subsections and should be at least 2-3 sentences at a minimum.

## Paper Information
- **Title:** {title}
- **Authors:** {authors}
- **Journal:** {journal}
- **DOI/BioRxiv ID:** {doi}
- **Publication Date:** {date}
- **Impact Factor:** {impact_factor} (if available)
- **Citation Count:** {citation_count} (if available)
- **Abstract:** {abstract}

## Paper Content (truncated for length):
{paper_text}

Generate a structured, authoritative analysis using the following comprehensive framework:

# Expert Analysis: {title}

## 1. Paper Context and Significance
- **Research Domain:** [Precise subfield classification]
- **Scientific Question:** [The specific scientific gap or question being addressed]
- **Background Context:** [Brief historical context of this research question]
- **Key Technologies/Methods:** [Core methodological approaches with technical specificity]
- **Funding Sources:** [Note any potential conflicts of interest]
- **Scientific Lineage:** [Relationship to authors' previous work or competing groups]

## 2. Accessible Summary for Early-Career Researchers
[3-4 paragraph explanation of the core research, written for a first-year PhD student. Balance accessibility with scientific precision. Define specialized terminology when first used. Highlight what makes this work novel or important in the broader context of the field.]

## 3. Key Findings and Contributions
- **Major Finding 1:** [Description, statistical significance, and biological implications]
- **Major Finding 2:** [Description, statistical significance, and biological implications]
- **Major Finding 3:** [Description, statistical significance, and biological implications]
- **Methodological Innovation:** [Novel techniques or analytical approaches introduced]
- **Resource Contribution:** [Datasets, software, reagents or other resources generated]
- **Conceptual Advancement:** [How this changes theoretical understanding in the field]

## 4. Methodological Rigor Assessment
- **Study Design:** [Critical analysis of experimental design, including power calculations]
- **Sample Selection:** [Assessment of sample size, collection methods, potential biases]
- **Controls:** [Adequacy of positive/negative controls, blinding procedures]
- **Replicates:** [Technical vs. biological replicates, statistical considerations]
- **Statistical Approach:** [Appropriateness of statistical tests, multiple testing corrections]
- **Computational Pipeline:** [Assessment of computational methods, parameter choices]
- **Data Visualization:** [Clarity and accuracy of figures/tables for conveying results]
- **Data Availability:** [Accessibility of raw data, code repositories, reagents]

## 5. Critical Evaluation

### 5.1. Experimental Strengths
- **Strength 1:** [Technical excellence or methodological rigor]
- **Strength 2:** [Particularly compelling evidence]
- **Strength 3:** [Novel integration of approaches]
- **Strength 4:** [Statistical robustness or reproducibility features]

### 5.2. Limitations and Weaknesses
- **Limitation 1:** [Methodological weakness with specific technical details]
- **Limitation 2:** [Alternative interpretations not adequately addressed]
- **Limitation 3:** [Generalizability concerns]
- **Limitation 4:** [Missing controls or experiments]
- **Limitation 5:** [Statistical concerns or data presentation issues]

### 5.3. Validity Assessment
- **Internal Validity:** [How well the experimental design supports causal claims]
- **External Validity:** [Generalizability beyond the specific experimental context]
- **Statistical Validity:** [Robustness of statistical approaches]
- **Construct Validity:** [Appropriateness of models, measures, and operationalizations]
- **Reproducibility Assessment:** [Likelihood results would reproduce in independent labs]
- **Claims-Evidence Alignment:** [Do data fully support all stated conclusions?]

## 6. Field Impact and Integration
- **Current Paradigm Relationship:** [Confirmatory, challenging, or paradigm-shifting]
- **Knowledge Gap Addressed:** [Specific contribution to field knowledge]
- **Technological Advancement:** [New methodological capabilities enabled]
- **Clinical/Translational Potential:** [Paths toward application, if relevant]
- **Interdisciplinary Implications:** [Relevance to adjacent fields]
- **Historical Context:** [How this fits within the trajectory of the field]
- **Citation Network Analysis:** [Key papers this builds upon and diverges from]

## 7. Computational Analysis (if applicable)
- **Dataset Characteristics:** [Size, structure, potential biases]
- **Algorithm Selection:** [Appropriateness of computational approaches]
- **Parameter Choices:** [Critical assessment of parameter selections]
- **Benchmarking:** [Comparison to alternative approaches]
- **Code Quality:** [Assessment of software implementation if available]
- **Computational Reproducibility:** [Ability to reproduce computational results]
- **Example Code:** [Toy example demonstrating key computational approach]

```python
# Example implementation of key algorithm with toy dataset if it's in python
import numpy as np
import pandas as pd
# [Include simplified implementation of core computational approach]
```

```r
# Example implementation of key algorithm with toy dataset if it's in R
library(dplyr)
# [Include simplified implementation of core computational approach]
```

## 8. Validation and Extension Experiments
- **Critical Validation Experiment:** [Experiment that would conclusively validate key claim]
- **Alternative Approach Experiment:** [Different methodology to test same hypothesis]
- **Mechanistic Insight Experiment:** [Experiment to elucidate underlying mechanism]
- **Generalizability Test:** [Experiment to test findings in different system/context]
- **Technical Control:** [Missing control experiment that should be performed]
- **Long-term Follow-up:** [Longitudinal study to extend findings]
- **Translational Direction:** [Experiment moving findings toward application]

## 9. Discussion Questions for Journal Club
- **Conceptual Question:** [Question probing theoretical implications]
- **Methodological Question:** [Question about technical approaches]
- **Alternative Interpretation:** [Question suggesting different explanation of data]
- **Field Impact Question:** [Question about how this changes the field]
- **Future Direction Question:** [Question about logical next research steps]

---

*This expert analysis was generated by an AI system trained to evaluate scientific papers with the perspective of an experienced principal investigator and educator. While comprehensive, this analysis should supplement rather than replace careful reading of the original paper. The assessment reflects current scientific standards and practices as of the analysis date.*